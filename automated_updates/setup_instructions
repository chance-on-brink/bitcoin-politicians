to set up the full automation pipeline:

  - create python virtual environment (3.11.6 or similar)
  - pip install -r requirements.txt
  - create .env file at automated_updates/.env (in working directory)
  - get an api key from congress gov and add to .env like this: CONGRESS_GOV_API_KEY = ''
  - download chromedriver from https://googlechromelabs.github.io/chrome-for-testing/, matching your chrome version and OS.
  - put the chromedriver executable path in .env like: CHROME_DRIVER_PATH = ''
  - get secret key from OpenAI, add funds as needed to use API. add key to .env like: OPENAI_API_KEY='sk-kiKX...'

  Note:
  if you get error:
  ModuleNotFoundError: No module named 'frontend'

  run:
  pip uninstall pymupdf
  pip install pymupdf


to run from scratch with a test dataset: 
  - modify folder paths in config.py (or just delete existing data)
      example:
        source_data_dir = './all_source_data_test/'
        intermediate_files_dir = './intermediate_files_test/'
        processed_data_dir = './all_processed_data_test/'
  - run gather script with flag: gather_source_data.py --test-set